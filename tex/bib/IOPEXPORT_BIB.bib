
  	
@article{0741-3335-56-11-114006,
  author={T Craciunescu and A Murari and M Gelfusa and I Tiseanu and V Zoita and JET EFDA Contributors},
  title={Overview of image processing tools to extract physical information from JET videos},
  journal={Plasma Physics and Controlled Fusion},
  volume={56},
  number={11},
  pages={114006},
  url={http://stacks.iop.org/0741-3335/56/i=11/a=114006},
  year={2014},
  abstract={In magnetic confinement nuclear fusion devices such as JET, the last few years have witnessed a significant increase in the use of digital imagery, not only for the surveying and control of experiments, but also for the physical interpretation of results. More than 25 cameras are routinely used for imaging on JET in the infrared (IR) and visible spectral regions. These cameras can produce up to tens of Gbytes per shot and their information content can be very different, depending on the experimental conditions. However, the relevant information about the underlying physical processes is generally of much reduced dimensionality compared to the recorded data. The extraction of this information, which allows full exploitation of these diagnostics, is a challenging task. The image analysis consists, in most cases, of inverse problems which are typically ill-posed mathematically. The typology of objects to be analysed is very wide, and usually the images are affected by noise, low levels of contrast, low grey-level in-depth resolution, reshaping of moving objects, etc. Moreover, the plasma events have time constants of ms or tens of ms, which imposes tough conditions for real-time applications. On JET, in the last few years new tools and methods have been developed for physical information retrieval. The methodology of optical flow has allowed, under certain assumptions, the derivation of information about the dynamics of video objects associated with different physical phenomena, such as instabilities, pellets and filaments. The approach has been extended in order to approximate the optical flow within the MPEG compressed domain, allowing the manipulation of the large JET video databases and, in specific cases, even real-time data processing. The fast visible camera may provide new information that is potentially useful for disruption prediction. A set of methods, based on the extraction of structural information from the visual scene, have been developed for the automatic detection of MARFE (multifaceted asymmetric radiation from the edge) occurrences, which precede disruptions in density limit discharges. An original spot detection method has been developed for large surveys of videos in JET, and for the assessment of the long term trends in their evolution. The analysis of JET IR videos, recorded during JET operation with the ITER-like wall, allows the retrieval of data and hence correlation of the evolution of spots properties with macroscopic events, in particular series of intentional disruptions.}
}
@inproceedings{Pa14Open,
  title={OpenCossan: An efficient open tool for dealing with epistemic and aleatory uncertainties},
  author={Patelli, E. and Broggi, M. and Angelis, M. de and Beer, M.},
  booktitle={Vulnerability, Uncertainty, and Risk},
  pages={2564--2573},
  year={2014},
  organization={American Society of Civil Engineers}
}
@book{dubuisson2015tracking,
  title={Tracking with Particle Filter for High-dimensional Observation and State Spaces},
  author={Dubuisson, S{\'e}verine},
  year={2015},
  publisher={John Wiley \& Sons}
}
@article{Blazakis2015495,
title = "Whole cell tracking through the optimal control of geometric evolution laws ",
journal = "Journal of Computational Physics ",
volume = "297",
number = "",
pages = "495 - 514",
year = "2015",
note = "",
issn = "0021-9991",
doi = "http://dx.doi.org/10.1016/j.jcp.2015.05.014",
url = "http://www.sciencedirect.com/science/article/pii/S0021999115003423",
author = "Konstantinos N. Blazakis and Anotida Madzvamuse and Constantino Carlos Reyes-Aldasoro and Vanessa Styles and Chandrasekhar Venkataraman",
keywords = "Cell tracking",
keywords = "Geometric evolution law",
keywords = "Optimal control",
keywords = "Phase field",
keywords = "Finite elements ",
abstract = "Abstract Cell tracking algorithms which automate and systematise the analysis of time lapse image data sets of cells are an indispensable tool in the modelling and understanding of cellular phenomena. In this study we present a theoretical framework and an algorithm for whole cell tracking. Within this work we consider that “tracking” is equivalent to a dynamic reconstruction of the whole cell data (morphologies) from static image data sets. The novelty of our work is that the tracking algorithm is driven by a model for the motion of the cell. This model may be regarded as a simplification of a recently developed physically meaningful model for cell motility. The resulting problem is the optimal control of a geometric evolution law and we discuss the formulation and numerical approximation of the optimal control problem. The overall goal of this work is to design a framework for cell tracking within which the recovered data reflects the physics of the forward model. A number of numerical simulations are presented that illustrate the applicability of our approach. "
}

@incollection{Meijering2012183,
title = "Chapter nine - Methods for Cell and Particle Tracking ",
editor = "P. Michael conn",
booktitle = "Imaging and Spectroscopic Analysis of Living CellsOptical and Spectroscopic Techniques",
publisher = "Academic Press",
year = "2012",
volume = "504",
pages = "183 - 200",
series = "Methods in Enzymology ",
issn = "0076-6879",
doi = "http://dx.doi.org/10.1016/B978-0-12-391857-4.00009-4",
url = "http://www.sciencedirect.com/science/article/pii/B9780123918574000094",
author = "Erik Meijering and Oleh Dzyubachyk and Ihor Smal",
keywords = "Cell tracking",
keywords = "Particle tracking",
keywords = "Image analysis",
keywords = "Motion analysis",
keywords = "Dynamics measures",
keywords = "Software tools ",
abstract = "Abstract Achieving complete understanding of any living thing inevitably requires thorough analysis of both its anatomic and dynamic properties. Live-cell imaging experiments carried out to this end often produce massive amounts of time-lapse image data containing far more information than can be digested by a human observer. Computerized image analysis offers the potential to take full advantage of available data in an efficient and reproducible manner. A recurring task in many experiments is the tracking of large numbers of cells or particles and the analysis of their (morpho)dynamic behavior. In the past decade, many methods have been developed for this purpose, and software tools based on these are increasingly becoming available. Here, we survey the latest developments in this area and discuss the various computational approaches, software tools, and quantitative measures for tracking and motion analysis of cells and particles in time-lapse microscopy images. "
}
@book{kalnay2003atmospheric,
  title={Atmospheric modeling, data assimilation, and predictability},
  author={Kalnay, Eugenia},
  year={2003},
  publisher={Cambridge university press}
}
@article{read2014general,
  title={General Circulation of Planetary Atmospheres: Insights from Rotating Annulus and Related Experiments},
  author={Read, Peter L and P{\'e}rez, Edgar P and Moroz, Irene M and Young, Roland MB},
  journal={Modeling Atmospheric and Oceanic Flows: Insights from Laboratory Experiments and Numerical Simulations},
  volume={205},
  year={2014},
  publisher={John Wiley \& Sons}
}
	
